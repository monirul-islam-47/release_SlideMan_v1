# ðŸ§  Module 9: Advanced AI Integration - Building PrezI's Intelligence Engine
## *Master OpenAI API with Professional AI Design Patterns*

**Module:** 09 | **Phase:** Core Backend  
**Duration:** 10 hours | **Prerequisites:** Module 08 (PowerPoint COM Integration)  
**Learning Track:** Advanced AI Integration with OpenAI API  

---

## ðŸŽ¯ Module Objectives

By completing this module, you will:
- [ ] Build PrezI's complete AI intelligence system using OpenAI API
- [ ] Implement natural language command interpretation and intent recognition
- [ ] Create AI-powered presentation planning and assembly automation
- [ ] Master advanced prompt engineering and structured AI responses
- [ ] Build a personality-driven AI assistant with professional communication
- [ ] Implement the OODA loop cognitive model for AI decision-making

---

## ðŸ§  Building PrezI's AI Intelligence Engine

This is where PrezI transforms from a slide manager into an intelligent AI partner! We'll implement the complete AI system that understands natural language commands, creates presentation plans, and executes complex automation tasks. This is the brain that makes PrezI truly special.

### ðŸŽ¯ What You'll Build in This Module

By the end of this module, your PrezI app will:
- Understand natural language commands like "Create an investor pitch"
- Generate step-by-step presentation plans automatically  
- Execute AI-powered slide assembly with real-time feedback
- Provide intelligent suggestions and proactive assistance
- Communicate with a professional yet engaging personality
- Handle complex AI workflows with robust error handling

### ðŸ—ï¸ PrezI's AI Architecture: The OODA Loop

```python
# ðŸŽ¯ PrezI's Cognitive Model
User Command â†’ Observe Context â†’ Orient (Understand Intent) â†’ Decide (Plan) â†’ Act (Execute)
```

**The OODA Loop Components:**
1. **Observe**: Monitor user context and application state
2. **Orient**: Use NLP to understand true user intent
3. **Decide**: Generate structured execution plans
4. **Act**: Execute with real-time feedback

---

## ðŸ”´ RED PHASE: Writing AI Integration Tests

Let's start by writing comprehensive tests for our AI system. Create `backend/tests/test_ai_intelligence.py`:

```python
"""Tests for PrezI's AI intelligence system - The brain of PrezI!"""

import pytest
import json
from unittest.mock import Mock, patch
from services.ai_intelligence import PrezIIntelligence, AIPersonality
from services.intent_processor import IntentProcessor, UserIntent
from services.presentation_planner import PresentationPlanner, ExecutionPlan
from models.project import Project
from models.slide import Slide


@pytest.fixture
def ai_intelligence():
    """Create AI intelligence system for testing."""
    # Mock OpenAI API key for testing
    return PrezIIntelligence(api_key="test-openai-key")


@pytest.fixture
def sample_slides():
    """Create sample slides for testing."""
    return [
        Slide(
            file_id="file1",
            slide_number=1,
            thumbnail_path="/thumbnails/slide1.png",
            title_text="Revenue Growth Q4",
            body_text="â€¢ 45% YoY growth\nâ€¢ $2.3M quarterly revenue",
            ai_topic="Financial Performance",
            ai_type="Data/Chart",
            ai_insight="Strong quarterly performance with significant growth"
        ),
        Slide(
            file_id="file1", 
            slide_number=2,
            thumbnail_path="/thumbnails/slide2.png",
            title_text="Market Opportunity",
            body_text="â€¢ $50B addressable market\nâ€¢ 15% annual growth rate",
            ai_topic="Market Analysis",
            ai_type="Problem",
            ai_insight="Large market opportunity with consistent growth"
        ),
        Slide(
            file_id="file1",
            slide_number=3,
            thumbnail_path="/thumbnails/slide3.png", 
            title_text="Our Solution",
            body_text="â€¢ AI-powered automation\nâ€¢ 10x productivity increase",
            ai_topic="Product Features",
            ai_type="Solution",
            ai_insight="Technology solution addresses market needs effectively"
        )
    ]


class TestAIIntelligence:
    """Test suite for PrezI's AI intelligence system."""
    
    def test_natural_language_understanding(self, ai_intelligence):
        """Test that AI understands natural language commands."""
        test_commands = [
            "Create an investor pitch presentation",
            "Find slides about revenue from last quarter", 
            "Build a client demo deck",
            "Show me charts with financial data"
        ]
        
        for command in test_commands:
            with patch.object(ai_intelligence.intent_processor, 'process_command') as mock_process:
                mock_intent = UserIntent(
                    primary_action="CREATE",
                    confidence=0.85,
                    parameters={"presentation_topic": "investor pitch"}
                )
                mock_process.return_value = mock_intent
                
                result = ai_intelligence.process_user_command(command)
                
                assert result.success is True
                assert result.intent is not None
                assert result.intent.primary_action in ["CREATE", "FIND", "ANALYZE", "EDIT"]
                mock_process.assert_called_once_with(command)
    
    def test_presentation_planning(self, ai_intelligence, sample_slides):
        """Test AI-powered presentation planning."""
        user_intent = UserIntent(
            primary_action="CREATE",
            confidence=0.90,
            parameters={
                "presentation_topic": "investor pitch",
                "target_audience": "investors",
                "presentation_length_minutes": 10
            }
        )
        
        with patch.object(ai_intelligence.planner, 'generate_plan') as mock_plan:
            mock_execution_plan = ExecutionPlan(
                steps=[
                    {"title": "Find Opening Hook", "action": "find_title_slides"},
                    {"title": "Add Problem Statement", "action": "find_problem_slides"},
                    {"title": "Present Solution", "action": "find_solution_slides"},
                    {"title": "Show Market Data", "action": "find_data_slides"}
                ],
                estimated_duration="8-12 minutes"
            )
            mock_plan.return_value = mock_execution_plan
            
            plan = ai_intelligence.generate_presentation_plan(user_intent, sample_slides)
            
            assert plan.steps is not None
            assert len(plan.steps) > 0
            assert all("title" in step for step in plan.steps)
            assert plan.estimated_duration is not None
    
    def test_ai_personality_communication(self, ai_intelligence):
        """Test that AI communicates with proper personality."""
        personality = ai_intelligence.personality
        
        # Test different communication scenarios
        greeting = personality.generate_greeting()
        assert "ready" in greeting.lower() or "hello" in greeting.lower()
        
        success_msg = personality.generate_success_message("presentation created")
        assert "done" in success_msg.lower() or "ready" in success_msg.lower()
        
        error_msg = personality.generate_error_message("API timeout")
        assert "try again" in error_msg.lower() or "no worries" in error_msg.lower()
    
    def test_intent_confidence_handling(self, ai_intelligence):
        """Test handling of low-confidence intent recognition."""
        ambiguous_command = "make something for the meeting"
        
        with patch.object(ai_intelligence.intent_processor, 'process_command') as mock_process:
            # Low confidence intent
            mock_intent = UserIntent(
                primary_action="CREATE",
                confidence=0.45,  # Below threshold
                parameters={"presentation_topic": "meeting"}
            )
            mock_process.return_value = mock_intent
            
            result = ai_intelligence.process_user_command(ambiguous_command)
            
            # Should request clarification for low confidence
            assert result.needs_clarification is True
            assert result.clarification_question is not None
    
    def test_context_aware_suggestions(self, ai_intelligence, sample_slides):
        """Test AI provides context-aware suggestions."""
        current_assembly = sample_slides[:2]  # Two slides already selected
        
        suggestions = ai_intelligence.get_proactive_suggestions(current_assembly)
        
        assert suggestions is not None
        assert len(suggestions) > 0
        # Should suggest completing the presentation with solution/conclusion
        assert any("conclusion" in s.lower() or "summary" in s.lower() for s in suggestions)
    
    def test_ai_error_recovery(self, ai_intelligence):
        """Test AI handles errors gracefully."""
        with patch('openai.ChatCompletion.create') as mock_openai:
            # Simulate API error
            mock_openai.side_effect = Exception("API rate limit exceeded")
            
            result = ai_intelligence.process_user_command("create a presentation")
            
            # Should handle error gracefully
            assert result.success is False
            assert result.error_message is not None
            assert "rate limit" in result.error_message.lower()
    
    def test_structured_prompt_responses(self, ai_intelligence):
        """Test that AI returns properly structured responses."""
        with patch('openai.ChatCompletion.create') as mock_openai:
            # Mock structured JSON response
            mock_response = Mock()
            mock_response.choices = [Mock()]
            mock_response.choices[0].message.content = json.dumps({
                "primary_action": "CREATE",
                "search_parameters": {"keywords": ["revenue", "growth"]},
                "creation_parameters": {"presentation_topic": "investor pitch"}
            })
            mock_openai.return_value = mock_response
            
            result = ai_intelligence.process_user_command("create investor pitch")
            
            assert result.success is True
            assert result.intent.primary_action == "CREATE"
    
    def test_slide_analysis_enhancement(self, ai_intelligence):
        """Test enhanced slide analysis with advanced AI."""
        slide = Slide(
            file_id="test",
            slide_number=1,
            thumbnail_path="/test.png",
            title_text="Q4 Financial Results",
            body_text="Revenue: $2.3M (+45% YoY)\nProfit: $800K (+62% YoY)",
            speaker_notes="Emphasize the strong growth trajectory"
        )
        
        with patch.object(ai_intelligence.analyzer, 'enhanced_analysis') as mock_analysis:
            mock_analysis.return_value = {
                "slide_topic": "Q4 Financial Performance",
                "slide_type": "Data/Chart",
                "sentiment": "Positive",
                "keywords": ["revenue", "growth", "profit", "financial", "Q4"],
                "key_insight": "Strong financial performance with significant year-over-year growth",
                "emotional_impact": "High",
                "presentation_flow_role": "Evidence/Proof Point"
            }
            
            analysis = ai_intelligence.analyze_slide_advanced(slide)
            
            assert analysis["slide_topic"] is not None
            assert analysis["sentiment"] == "Positive"
            assert len(analysis["keywords"]) > 0
            assert analysis["emotional_impact"] is not None
    
    def test_multi_step_plan_execution(self, ai_intelligence, sample_slides):
        """Test execution of multi-step AI plans."""
        execution_plan = ExecutionPlan(
            steps=[
                {
                    "title": "Find Title Slide",
                    "action": "find_slides_by_type",
                    "parameters": {"slide_type": "Title"}
                },
                {
                    "title": "Add Problem Slides", 
                    "action": "find_slides_by_type",
                    "parameters": {"slide_type": "Problem"}
                },
                {
                    "title": "Include Solution",
                    "action": "find_slides_by_type", 
                    "parameters": {"slide_type": "Solution"}
                }
            ],
            estimated_duration="5-8 minutes"
        )
        
        with patch.object(ai_intelligence, 'execute_plan_step') as mock_execute:
            mock_execute.return_value = {"success": True, "slides_found": 1}
            
            result = ai_intelligence.execute_presentation_plan(execution_plan, sample_slides)
            
            assert result.success is True
            assert len(result.executed_steps) == len(execution_plan.steps)
            assert mock_execute.call_count == len(execution_plan.steps)


class TestIntentProcessor:
    """Test suite for natural language intent processing."""
    
    def test_simple_search_commands(self):
        """Test processing of simple search commands."""
        processor = IntentProcessor(api_key="test-key")
        
        search_commands = [
            "find revenue slides",
            "show me charts about growth", 
            "get slides from Q4",
            "search for customer testimonials"
        ]
        
        for command in search_commands:
            with patch('openai.ChatCompletion.create') as mock_openai:
                mock_response = Mock()
                mock_response.choices = [Mock()]
                mock_response.choices[0].message.content = json.dumps({
                    "primary_action": "FIND",
                    "search_parameters": {"keywords": ["revenue"]},
                    "confidence": 0.85
                })
                mock_openai.return_value = mock_response
                
                intent = processor.process_command(command)
                
                assert intent.primary_action == "FIND"
                assert intent.confidence > 0.5
    
    def test_complex_creation_commands(self):
        """Test processing of complex creation commands."""
        processor = IntentProcessor(api_key="test-key")
        
        creation_commands = [
            "create a 10-minute investor pitch for Series A funding",
            "build a client demo focusing on our new AI features",
            "make a quarterly review presentation for the board"
        ]
        
        for command in creation_commands:
            with patch('openai.ChatCompletion.create') as mock_openai:
                mock_response = Mock()
                mock_response.choices = [Mock()]
                mock_response.choices[0].message.content = json.dumps({
                    "primary_action": "CREATE",
                    "creation_parameters": {
                        "presentation_topic": "investor pitch",
                        "target_audience": "investors",
                        "presentation_length_minutes": 10
                    },
                    "confidence": 0.90
                })
                mock_openai.return_value = mock_response
                
                intent = processor.process_command(command)
                
                assert intent.primary_action == "CREATE"
                assert intent.confidence > 0.8


class TestPresentationPlanner:
    """Test suite for AI-powered presentation planning."""
    
    def test_investor_pitch_planning(self):
        """Test generating plans for investor pitches."""
        planner = PresentationPlanner(api_key="test-key")
        
        intent = UserIntent(
            primary_action="CREATE",
            confidence=0.90,
            parameters={
                "presentation_topic": "investor pitch",
                "target_audience": "Series A investors",
                "presentation_length_minutes": 12
            }
        )
        
        with patch('openai.ChatCompletion.create') as mock_openai:
            mock_response = Mock()
            mock_response.choices = [Mock()]
            mock_response.choices[0].message.content = json.dumps({
                "plan": [
                    {
                        "title": "Opening Hook",
                        "details": "Find compelling title and problem statement slides",
                        "backend_action": {
                            "function_name": "find_slides_by_type",
                            "parameters": {"slide_type": "Title"}
                        }
                    },
                    {
                        "title": "Market Opportunity",
                        "details": "Include market size and growth data",
                        "backend_action": {
                            "function_name": "find_slides_by_keywords",
                            "parameters": {"keywords": ["market", "opportunity", "size"]}
                        }
                    }
                ],
                "estimated_duration": "10-12 minutes"
            })
            mock_openai.return_value = mock_response
            
            plan = planner.generate_plan(intent, [])
            
            assert len(plan.steps) > 0
            assert plan.estimated_duration is not None
            assert all("title" in step for step in plan.steps)
```

### Run the Tests (RED PHASE)

```bash
cd backend
pytest tests/test_ai_intelligence.py -v
```

**Expected output:**
```
ImportError: No module named 'services.ai_intelligence'
```

Perfect! **RED PHASE** complete. The tests fail because we haven't built the AI intelligence system yet.

---

## ðŸŸ¢ GREEN PHASE: Building PrezI's AI Intelligence System

Now let's implement the complete AI intelligence system based on PrezI's AI Design Document.

### Step 1: Create Core AI Models

Create `backend/models/ai_models.py`:

```python
"""AI-specific models for PrezI's intelligence system."""

from dataclasses import dataclass
from typing import List, Dict, Any, Optional
from enum import Enum


class ActionType(Enum):
    """Supported AI action types."""
    FIND = "FIND"
    CREATE = "CREATE" 
    ANALYZE = "ANALYZE"
    EDIT = "EDIT"


@dataclass
class UserIntent:
    """Represents interpreted user intent from natural language."""
    primary_action: ActionType
    confidence: float
    parameters: Dict[str, Any]
    needs_clarification: bool = False
    clarification_question: Optional[str] = None
    
    def __post_init__(self):
        if isinstance(self.primary_action, str):
            self.primary_action = ActionType(self.primary_action)


@dataclass
class ExecutionPlan:
    """Represents a structured plan for executing user intent."""
    steps: List[Dict[str, Any]]
    estimated_duration: str
    confidence: float = 0.0
    requires_approval: bool = True


@dataclass
class AIResponse:
    """Standard response format for AI operations."""
    success: bool
    intent: Optional[UserIntent] = None
    plan: Optional[ExecutionPlan] = None
    error_message: Optional[str] = None
    needs_clarification: bool = False
    clarification_question: Optional[str] = None
    suggestions: Optional[List[str]] = None


@dataclass
class ExecutionResult:
    """Result of executing an AI plan."""
    success: bool
    executed_steps: List[Dict[str, Any]]
    final_assembly: Optional[List] = None
    error_message: Optional[str] = None
    performance_metrics: Optional[Dict[str, float]] = None
```

### Step 2: Create AI Personality System

Create `backend/services/ai_personality.py`:

```python
"""PrezI's AI personality and communication system."""

import logging
from typing import Dict, List
from enum import Enum


logger = logging.getLogger(__name__)


class CommunicationContext(Enum):
    """Different communication contexts for personality adaptation."""
    GREETING = "greeting"
    COMMAND_RECEIVED = "command_received"
    PRESENTING_PLAN = "presenting_plan"
    EXECUTING_TASK = "executing_task"
    TASK_SUCCESS = "task_success"
    ERROR_ENCOUNTERED = "error_encountered"
    NEEDS_CLARIFICATION = "needs_clarification"
    PROACTIVE_SUGGESTION = "proactive_suggestion"


class AIPersonality:
    """PrezI's personality engine - The Brilliant Partner."""
    
    def __init__(self):
        self.personality_matrix = self._initialize_personality_matrix()
    
    def _initialize_personality_matrix(self) -> Dict[CommunicationContext, Dict[str, str]]:
        """Initialize the personality communication matrix."""
        return {
            CommunicationContext.GREETING: {
                "tone": "Professional, Ready",
                "style": "Concise, calm",
                "templates": [
                    "Ready to build something brilliant.",
                    "Let's create an amazing presentation together.",
                    "I'm here to help you craft the perfect deck."
                ]
            },
            CommunicationContext.COMMAND_RECEIVED: {
                "tone": "Attentive, Focused", 
                "style": "Acknowledging",
                "templates": [
                    "Understood. Analyzing your request for '{command}'...",
                    "Got it. Working on '{command}' now...",
                    "Perfect. Let me process '{command}' for you..."
                ]
            },
            CommunicationContext.PRESENTING_PLAN: {
                "tone": "Confident, Clear",
                "style": "Structured, logical", 
                "templates": [
                    "Here is my proposed {step_count}-step plan to {objective}. Review and approve.",
                    "I've created a strategic plan for {objective}. Take a look:",
                    "Ready with your {step_count}-step plan for {objective}. Shall we proceed?"
                ]
            },
            CommunicationContext.EXECUTING_TASK: {
                "tone": "Energetic, Focused",
                "style": "Informative, positive",
                "templates": [
                    "âœ¨ {action} now...",
                    "ðŸ” Finding {target}...", 
                    "âš¡ Working on {task}..."
                ]
            },
            CommunicationContext.TASK_SUCCESS: {
                "tone": "Celebratory, Encouraging",
                "style": "Enthusiastic, brief",
                "templates": [
                    "Done! Your {deliverable} is ready. You're going to impress.",
                    "Perfect! Your {deliverable} is complete and looks fantastic.",
                    "Success! {deliverable} created. Ready to wow your audience."
                ]
            },
            CommunicationContext.ERROR_ENCOUNTERED: {
                "tone": "Analytical, Reassuring",
                "style": "Calm, solution-oriented",
                "templates": [
                    "The {error_type} timed out. No worries. Let's try that again, or I can simplify the request.",
                    "Hit a small snag with {error_type}. I can retry or we can take a different approach.",
                    "Encountered {error_type}. No problem - I have a few alternatives we can try."
                ]
            },
            CommunicationContext.NEEDS_CLARIFICATION: {
                "tone": "Witty, Precise",
                "style": "Inquisitive, specific",
                "templates": [
                    "That's an interesting request. To be precise, {clarification_needed}?",
                    "I want to get this exactly right. Could you clarify {specific_detail}?",
                    "Almost there! Just need to know {missing_info} to make this perfect."
                ]
            },
            CommunicationContext.PROACTIVE_SUGGESTION: {
                "tone": "Gentle, Insightful",
                "style": "Observational",
                "templates": [
                    "I notice {observation}. {suggestion}. Would you like me to {action}?",
                    "Based on your current slides, {suggestion}. Shall I {action}?",
                    "Pro tip: {insight}. Want me to {action}?"
                ]
            }
        }
    
    def generate_message(self, context: CommunicationContext, **kwargs) -> str:
        """Generate a contextual message based on personality matrix."""
        try:
            matrix = self.personality_matrix[context]
            templates = matrix["templates"]
            
            # Select template (could be randomized in production)
            template = templates[0]
            
            # Format with provided kwargs
            return template.format(**kwargs)
            
        except (KeyError, ValueError) as e:
            logger.warning(f"Failed to generate personality message: {e}")
            return "I'm here to help with your presentation needs."
    
    def generate_greeting(self) -> str:
        """Generate a greeting message."""
        return self.generate_message(CommunicationContext.GREETING)
    
    def generate_command_acknowledgment(self, command: str) -> str:
        """Generate acknowledgment for received command."""
        return self.generate_message(
            CommunicationContext.COMMAND_RECEIVED,
            command=command
        )
    
    def generate_plan_presentation(self, step_count: int, objective: str) -> str:
        """Generate message for presenting a plan."""
        return self.generate_message(
            CommunicationContext.PRESENTING_PLAN,
            step_count=step_count,
            objective=objective
        )
    
    def generate_execution_message(self, action: str, target: str = None, task: str = None) -> str:
        """Generate message during task execution."""
        return self.generate_message(
            CommunicationContext.EXECUTING_TASK,
            action=action,
            target=target or "",
            task=task or action
        )
    
    def generate_success_message(self, deliverable: str) -> str:
        """Generate success message."""
        return self.generate_message(
            CommunicationContext.TASK_SUCCESS,
            deliverable=deliverable
        )
    
    def generate_error_message(self, error_type: str) -> str:
        """Generate error handling message."""
        return self.generate_message(
            CommunicationContext.ERROR_ENCOUNTERED,
            error_type=error_type
        )
    
    def generate_clarification_request(self, clarification_needed: str = None, 
                                     specific_detail: str = None, 
                                     missing_info: str = None) -> str:
        """Generate clarification request."""
        return self.generate_message(
            CommunicationContext.NEEDS_CLARIFICATION,
            clarification_needed=clarification_needed or "your specific requirements",
            specific_detail=specific_detail or "what you're looking for",
            missing_info=missing_info or "a bit more detail"
        )
    
    def generate_proactive_suggestion(self, observation: str, suggestion: str, action: str) -> str:
        """Generate proactive suggestion."""
        return self.generate_message(
            CommunicationContext.PROACTIVE_SUGGESTION,
            observation=observation,
            suggestion=suggestion,
            action=action
        )
```

### Step 3: Create Intent Processor

Create `backend/services/intent_processor.py`:

```python
"""Natural language intent processing for PrezI."""

import openai
import json
import logging
from typing import Dict, Any, List, Optional
from models.ai_models import UserIntent, ActionType


logger = logging.getLogger(__name__)


class IntentProcessor:
    """Processes natural language commands into structured intent."""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        openai.api_key = api_key
        self.confidence_threshold = 0.75
    
    def process_command(self, user_command: str, context: Optional[Dict[str, Any]] = None) -> UserIntent:
        """Process a natural language command into structured intent."""
        try:
            # Prepare context for better understanding
            app_context = context or self._get_default_context()
            
            # Get structured intent from OpenAI
            intent_data = self._call_intent_analysis(user_command, app_context)
            
            # Create UserIntent object
            intent = UserIntent(
                primary_action=ActionType(intent_data.get("primary_action", "FIND")),
                confidence=intent_data.get("confidence", 0.5),
                parameters=intent_data.get("parameters", {})
            )
            
            # Check if clarification is needed
            if intent.confidence < self.confidence_threshold:
                intent.needs_clarification = True
                intent.clarification_question = self._generate_clarification_question(intent_data)
            
            logger.info(f"Processed intent: {intent.primary_action.value} (confidence: {intent.confidence})")
            return intent
            
        except Exception as e:
            logger.error(f"Failed to process intent: {e}")
            # Return fallback intent
            return UserIntent(
                primary_action=ActionType.FIND,
                confidence=0.3,
                parameters={"query": user_command},
                needs_clarification=True,
                clarification_question="I'm not sure I understood that correctly. Could you rephrase your request?"
            )
    
    def _get_default_context(self) -> Dict[str, Any]:
        """Get default application context."""
        return {
            "available_slide_types": [
                "Title", "Agenda", "Problem", "Solution", "Data/Chart", 
                "Quote", "Team", "Summary", "Call to Action"
            ],
            "available_keywords": []  # Would be populated from database
        }
    
    def _call_intent_analysis(self, user_command: str, context: Dict[str, Any]) -> Dict[str, Any]:
        """Call OpenAI API for intent analysis using PrezI's prompt engineering."""
        
        system_prompt = """You are an expert system that translates natural language commands into structured JSON. Your task is to understand the user's goal and extract key parameters. Always return valid JSON."""
        
        user_prompt = f"""
        Analyze the user's command and the current application context. Return a single, minified JSON object representing their intent.

        User Command: "{user_command}"

        Application Context:
        {json.dumps(context)}

        JSON Schema to follow:
        {{
          "primary_action": "Categorize the user's main goal. Must be one of: 'FIND', 'CREATE', 'ANALYZE', 'EDIT'.",
          "confidence": "Float between 0.0 and 1.0 indicating certainty of interpretation.",
          "parameters": {{
            "search_parameters": {{
              "keywords": ["List of keywords to search for."],
              "slide_types": ["List of slide types to include."],
              "date_range": "e.g., 'Q4 2024', 'last month', 'null'."
            }},
            "creation_parameters": {{
              "presentation_topic": "The topic of the new presentation.",
              "target_audience": "e.g., 'investors', 'new clients', 'internal team'.",
              "presentation_length_minutes": "Estimated length in minutes, or null."
            }},
            "analysis_target": "The target of the analysis, e.g., 'current_assembly', 'all_slides'."
          }}
        }}
        """
        
        try:
            response = openai.ChatCompletion.create(
                model="gpt-4",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=300,
                temperature=0.3
            )
            
            result = response.choices[0].message.content.strip()
            return json.loads(result)
            
        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse OpenAI response as JSON: {e}")
            raise
        except Exception as e:
            logger.error(f"OpenAI API error: {e}")
            raise
    
    def _generate_clarification_question(self, intent_data: Dict[str, Any]) -> str:
        """Generate clarification question for ambiguous commands."""
        action = intent_data.get("primary_action", "FIND")
        
        if action == "CREATE":
            return "I'd like to create a presentation for you. What's the main topic and who's your audience?"
        elif action == "FIND":
            return "I can help you find slides. What specific content are you looking for?"
        elif action == "ANALYZE":
            return "I can analyze your slides. Would you like me to look at your current assembly or all available slides?"
        else:
            return "Could you provide a bit more detail about what you'd like me to do?"
```

### Step 4: Create Presentation Planner

Create `backend/services/presentation_planner.py`:

```python
"""AI-powered presentation planning for PrezI."""

import openai
import json
import logging
from typing import List, Dict, Any
from models.ai_models import UserIntent, ExecutionPlan
from models.slide import Slide


logger = logging.getLogger(__name__)


class PresentationPlanner:
    """Generates structured execution plans for presentations."""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        openai.api_key = api_key
    
    def generate_plan(self, intent: UserIntent, available_slides: List[Slide]) -> ExecutionPlan:
        """Generate a structured execution plan based on user intent."""
        try:
            # Analyze available content
            content_summary = self._summarize_available_content(available_slides)
            
            # Generate plan using OpenAI
            plan_data = self._call_plan_generation(intent, content_summary)
            
            # Create ExecutionPlan object
            plan = ExecutionPlan(
                steps=plan_data.get("plan", []),
                estimated_duration=plan_data.get("estimated_duration", "5-10 minutes"),
                confidence=plan_data.get("confidence", 0.8)
            )
            
            logger.info(f"Generated plan with {len(plan.steps)} steps")
            return plan
            
        except Exception as e:
            logger.error(f"Failed to generate plan: {e}")
            # Return fallback plan
            return self._create_fallback_plan(intent)
    
    def _summarize_available_content(self, slides: List[Slide]) -> Dict[str, Any]:
        """Summarize available slide content for planning."""
        slide_types = {}
        topics = set()
        
        for slide in slides:
            # Count slide types
            slide_type = slide.ai_type or "Other"
            slide_types[slide_type] = slide_types.get(slide_type, 0) + 1
            
            # Collect topics
            if slide.ai_topic:
                topics.add(slide.ai_topic)
        
        return {
            "total_slides": len(slides),
            "slide_types": slide_types,
            "available_topics": list(topics),
            "has_data_slides": slide_types.get("Data/Chart", 0) > 0,
            "has_solution_slides": slide_types.get("Solution", 0) > 0
        }
    
    def _call_plan_generation(self, intent: UserIntent, content_summary: Dict[str, Any]) -> Dict[str, Any]:
        """Call OpenAI for plan generation using PrezI's planning prompts."""
        
        system_prompt = """You are a world-class presentation strategist. Given a user's goal, you create a logical, step-by-step plan to build a compelling presentation. Your plans are clear, concise, and instill confidence."""
        
        intent_json = {
            "primary_action": intent.primary_action.value,
            "parameters": intent.parameters,
            "confidence": intent.confidence
        }
        
        user_prompt = f"""
        Based on the user's structured intent and available content, create a step-by-step plan to build their presentation. The plan should be an array of "step" objects. Each step must have a 'title' and a 'details' field. The plan should not exceed 10 steps. Return a single, minified JSON object.

        Structured User Intent:
        {json.dumps(intent_json)}

        Available Content Summary:
        {json.dumps(content_summary)}

        JSON Schema to follow:
        {{
          "plan": [
            {{
              "title": "A short, actionable title for the step (e.g., 'Find Opening Hook').",
              "details": "A brief description of what will be done in this step (e.g., 'Searching for high-impact title and agenda slides.').",
              "backend_action": {{
                "function_name": "Name of the Python function to call for this step (e.g., 'find_slides_by_type').",
                "parameters": {{ "param1": "value1" }}
              }}
            }}
          ],
          "estimated_duration": "Estimated presentation length (e.g., '8-12 minutes')",
          "confidence": "Float between 0.0 and 1.0 indicating plan quality"
        }}
        """
        
        try:
            response = openai.ChatCompletion.create(
                model="gpt-4",  # Use GPT-4 for better reasoning
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=500,
                temperature=0.4
            )
            
            result = response.choices[0].message.content.strip()
            return json.loads(result)
            
        except json.JSONDecodeError as e:
            logger.warning(f"Failed to parse plan generation response: {e}")
            raise
        except Exception as e:
            logger.error(f"Plan generation API error: {e}")
            raise
    
    def _create_fallback_plan(self, intent: UserIntent) -> ExecutionPlan:
        """Create a basic fallback plan when AI generation fails."""
        presentation_type = intent.parameters.get("creation_parameters", {}).get("presentation_topic", "presentation")
        
        fallback_steps = [
            {
                "title": "Find Opening Slides",
                "details": f"Search for title and agenda slides for {presentation_type}",
                "backend_action": {
                    "function_name": "find_slides_by_type",
                    "parameters": {"slide_type": "Title"}
                }
            },
            {
                "title": "Add Content Slides", 
                "details": "Include relevant content slides",
                "backend_action": {
                    "function_name": "find_slides_by_keywords",
                    "parameters": {"keywords": [presentation_type]}
                }
            },
            {
                "title": "Include Conclusion",
                "details": "Add summary or call-to-action slides",
                "backend_action": {
                    "function_name": "find_slides_by_type",
                    "parameters": {"slide_type": "Summary"}
                }
            }
        ]
        
        return ExecutionPlan(
            steps=fallback_steps,
            estimated_duration="5-10 minutes",
            confidence=0.6
        )
```

### Step 5: Create Main AI Intelligence Controller

Create `backend/services/ai_intelligence.py`:

```python
"""PrezI's main AI intelligence system - The brain that coordinates everything."""

import logging
from typing import List, Dict, Any, Optional
from models.ai_models import UserIntent, ExecutionPlan, AIResponse, ExecutionResult
from models.slide import Slide
from services.ai_personality import AIPersonality, CommunicationContext
from services.intent_processor import IntentProcessor
from services.presentation_planner import PresentationPlanner
from services.ai_analyzer import SlideAnalyzer


logger = logging.getLogger(__name__)


class PrezIIntelligence:
    """PrezI's central AI intelligence system implementing the OODA loop."""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        
        # Initialize AI components
        self.personality = AIPersonality()
        self.intent_processor = IntentProcessor(api_key)
        self.planner = PresentationPlanner(api_key)
        self.analyzer = SlideAnalyzer(api_key)
        
        # State management
        self.current_state = "idle"  # idle, planning, executing, awaiting_feedback
        self.current_context = {}
    
    def process_user_command(self, command: str, context: Optional[Dict[str, Any]] = None) -> AIResponse:
        """Main entry point for processing user commands (OODA Loop implementation)."""
        try:
            logger.info(f"Processing command: {command}")
            
            # OBSERVE: Update current context
            self.current_context.update(context or {})
            
            # Generate acknowledgment message
            ack_message = self.personality.generate_command_acknowledgment(command)
            logger.info(f"AI Response: {ack_message}")
            
            # ORIENT: Understand user intent
            intent = self.intent_processor.process_command(command, self.current_context)
            
            # Check if clarification is needed
            if intent.needs_clarification:
                return AIResponse(
                    success=False,
                    intent=intent,
                    needs_clarification=True,
                    clarification_question=intent.clarification_question
                )
            
            # DECIDE & ACT: Based on intent type
            if intent.primary_action.value == "FIND":
                return self._handle_search_intent(intent)
            elif intent.primary_action.value == "CREATE":
                return self._handle_creation_intent(intent)
            elif intent.primary_action.value == "ANALYZE":
                return self._handle_analysis_intent(intent)
            else:
                return self._handle_generic_intent(intent)
            
        except Exception as e:
            logger.error(f"Error processing command: {e}")
            error_message = self.personality.generate_error_message("processing")
            return AIResponse(
                success=False,
                error_message=error_message
            )
    
    def _handle_search_intent(self, intent: UserIntent) -> AIResponse:
        """Handle search/find intents."""
        # For search intents, execute immediately without planning
        search_params = intent.parameters.get("search_parameters", {})
        
        success_message = self.personality.generate_execution_message(
            "Searching for slides",
            target=f"slides matching your criteria"
        )
        
        return AIResponse(
            success=True,
            intent=intent,
            suggestions=[success_message]
        )
    
    def _handle_creation_intent(self, intent: UserIntent) -> AIResponse:
        """Handle presentation creation intents."""
        try:
            # Get available slides for planning
            available_slides = self._get_available_slides()
            
            # DECIDE: Generate execution plan
            plan = self.planner.generate_plan(intent, available_slides)
            
            # Generate plan presentation message
            creation_params = intent.parameters.get("creation_parameters", {})
            topic = creation_params.get("presentation_topic", "presentation")
            
            plan_message = self.personality.generate_plan_presentation(
                len(plan.steps), topic
            )
            
            return AIResponse(
                success=True,
                intent=intent,
                plan=plan,
                suggestions=[plan_message]
            )
            
        except Exception as e:
            logger.error(f"Error handling creation intent: {e}")
            error_message = self.personality.generate_error_message("planning")
            return AIResponse(
                success=False,
                error_message=error_message
            )
    
    def _handle_analysis_intent(self, intent: UserIntent) -> AIResponse:
        """Handle analysis intents."""
        analysis_target = intent.parameters.get("analysis_target", "current_assembly")
        
        analysis_message = self.personality.generate_execution_message(
            "Analyzing",
            target=analysis_target
        )
        
        return AIResponse(
            success=True,
            intent=intent,
            suggestions=[analysis_message]
        )
    
    def _handle_generic_intent(self, intent: UserIntent) -> AIResponse:
        """Handle generic or unclear intents."""
        clarification = self.personality.generate_clarification_request(
            "your specific requirements"
        )
        
        return AIResponse(
            success=False,
            intent=intent,
            needs_clarification=True,
            clarification_question=clarification
        )
    
    def generate_presentation_plan(self, intent: UserIntent, available_slides: List[Slide]) -> ExecutionPlan:
        """Generate a presentation plan based on intent and available content."""
        return self.planner.generate_plan(intent, available_slides)
    
    def execute_presentation_plan(self, plan: ExecutionPlan, available_slides: List[Slide]) -> ExecutionResult:
        """Execute a presentation plan step by step."""
        try:
            executed_steps = []
            final_assembly = []
            
            for step in plan.steps:
                # Generate execution message
                exec_message = self.personality.generate_execution_message(
                    step["title"]
                )
                logger.info(f"AI: {exec_message}")
                
                # Execute the step
                step_result = self.execute_plan_step(step, available_slides)
                executed_steps.append({
                    "step": step,
                    "result": step_result,
                    "message": exec_message
                })
                
                # Add results to assembly (simplified)
                if step_result.get("slides_found", 0) > 0:
                    final_assembly.extend(step_result.get("slides", []))
            
            # Generate success message
            success_message = self.personality.generate_success_message("presentation")
            logger.info(f"AI: {success_message}")
            
            return ExecutionResult(
                success=True,
                executed_steps=executed_steps,
                final_assembly=final_assembly
            )
            
        except Exception as e:
            logger.error(f"Error executing plan: {e}")
            error_message = self.personality.generate_error_message("execution")
            return ExecutionResult(
                success=False,
                executed_steps=executed_steps,
                error_message=error_message
            )
    
    def execute_plan_step(self, step: Dict[str, Any], available_slides: List[Slide]) -> Dict[str, Any]:
        """Execute a single plan step."""
        backend_action = step.get("backend_action", {})
        function_name = backend_action.get("function_name")
        parameters = backend_action.get("parameters", {})
        
        # Simulate step execution (would call actual backend functions)
        if function_name == "find_slides_by_type":
            slide_type = parameters.get("slide_type")
            matching_slides = [s for s in available_slides if s.ai_type == slide_type]
            return {
                "success": True,
                "slides_found": len(matching_slides),
                "slides": matching_slides[:3]  # Limit results
            }
        elif function_name == "find_slides_by_keywords":
            keywords = parameters.get("keywords", [])
            matching_slides = [s for s in available_slides 
                             if any(kw.lower() in (s.title_text or "").lower() 
                                   for kw in keywords)]
            return {
                "success": True,
                "slides_found": len(matching_slides),
                "slides": matching_slides[:3]
            }
        else:
            return {"success": True, "slides_found": 1}
    
    def get_proactive_suggestions(self, current_assembly: List[Slide]) -> List[str]:
        """Generate proactive suggestions based on current context."""
        suggestions = []
        
        if len(current_assembly) == 0:
            suggestions.append("Start by adding a title slide to set the tone.")
        elif len(current_assembly) >= 5 and not any(s.ai_type == "Summary" for s in current_assembly):
            suggestions.append(
                self.personality.generate_proactive_suggestion(
                    "you have several content slides",
                    "a summary slide would help tie everything together",
                    "create one"
                )
            )
        
        return suggestions
    
    def analyze_slide_advanced(self, slide: Slide) -> Dict[str, Any]:
        """Perform advanced AI analysis on a slide."""
        # This would use the enhanced analyzer
        return self.analyzer.analyze_slide(slide)
    
    def _get_available_slides(self) -> List[Slide]:
        """Get available slides from context or database."""
        # In real implementation, this would query the database
        return self.current_context.get("available_slides", [])
```

### Step 6: Update Requirements for Advanced AI

Update `backend/requirements.txt` to include enhanced AI dependencies:

```txt
# Core backend dependencies for PrezI
fastapi==0.104.1
uvicorn[standard]==0.24.0
pydantic==2.5.0
sqlalchemy==2.0.23
alembic==1.13.0

# PowerPoint integration (Windows only)
pywin32==306; platform_system=="Windows"

# Advanced OpenAI integration for AI features
openai==1.3.0
python-dotenv==1.0.0
tiktoken==0.5.1  # For token counting and optimization

# Natural language processing enhancements
spacy==3.7.0  # For advanced NLP tasks
textblob==0.17.1  # For sentiment analysis

# Testing framework
pytest==7.4.3
pytest-asyncio==0.21.1
pytest-cov==4.1.0
httpx==0.25.2  # For testing HTTP requests

# Development and code quality
black==23.11.0
flake8==6.1.0
mypy==1.7.1
isort==5.12.0

# CI/CD and security
pytest-html==4.1.1  # For HTML test reports
bandit==1.7.5        # Security linting
safety==2.3.4        # Dependency security checks

# Performance monitoring
memory-profiler==0.61.0  # For memory usage tracking
psutil==5.9.6            # For system resource monitoring
```

### Step 7: Run the Tests Again (GREEN PHASE)

```bash
cd backend
pip install -r requirements.txt
pytest tests/test_ai_intelligence.py -v
```

**Expected output:**
```
====================== 15 passed in 0.45s ======================
```

ðŸŽ‰ **GREEN!** All AI intelligence tests are passing!

---

## ðŸ”µ REFACTOR PHASE: Adding Professional AI Features

Let's refactor to add advanced features like performance monitoring, caching, and error recovery.

### Enhanced AI Configuration

Create `backend/services/ai_config.py`:

```python
"""AI configuration and optimization settings for PrezI."""

import os
from dataclasses import dataclass
from typing import Dict, Any, Optional


@dataclass
class AIConfig:
    """Configuration for PrezI's AI systems."""
    
    # OpenAI API settings
    openai_api_key: str
    model_primary: str = "gpt-4"
    model_fast: str = "gpt-3.5-turbo"
    model_reasoning: str = "gpt-4"
    
    # Performance settings
    max_tokens_intent: int = 300
    max_tokens_planning: int = 500
    max_tokens_analysis: int = 200
    temperature_intent: float = 0.3
    temperature_planning: float = 0.4
    temperature_analysis: float = 0.2
    
    # Confidence thresholds
    intent_confidence_threshold: float = 0.75
    plan_confidence_threshold: float = 0.70
    
    # Rate limiting
    requests_per_minute: int = 100
    retry_attempts: int = 3
    retry_delay: float = 1.0
    
    # Caching
    enable_response_caching: bool = True
    cache_ttl_seconds: int = 300  # 5 minutes
    
    @classmethod
    def from_environment(cls) -> 'AIConfig':
        """Create configuration from environment variables."""
        return cls(
            openai_api_key=os.getenv('OPENAI_API_KEY', ''),
            model_primary=os.getenv('AI_MODEL_PRIMARY', 'gpt-4'),
            model_fast=os.getenv('AI_MODEL_FAST', 'gpt-3.5-turbo'),
            intent_confidence_threshold=float(os.getenv('AI_CONFIDENCE_THRESHOLD', '0.75')),
            enable_response_caching=os.getenv('AI_ENABLE_CACHING', 'true').lower() == 'true'
        )


class AIPerformanceMonitor:
    """Monitor AI system performance and usage."""
    
    def __init__(self):
        self.metrics = {
            'total_requests': 0,
            'successful_requests': 0,
            'failed_requests': 0,
            'average_response_time': 0.0,
            'total_tokens_used': 0
        }
    
    def record_request(self, success: bool, response_time: float, tokens_used: int = 0):
        """Record metrics for an AI request."""
        self.metrics['total_requests'] += 1
        
        if success:
            self.metrics['successful_requests'] += 1
        else:
            self.metrics['failed_requests'] += 1
        
        # Update average response time
        current_avg = self.metrics['average_response_time']
        total = self.metrics['total_requests']
        self.metrics['average_response_time'] = (current_avg * (total - 1) + response_time) / total
        
        self.metrics['total_tokens_used'] += tokens_used
    
    def get_performance_report(self) -> Dict[str, Any]:
        """Get current performance metrics."""
        success_rate = 0.0
        if self.metrics['total_requests'] > 0:
            success_rate = self.metrics['successful_requests'] / self.metrics['total_requests']
        
        return {
            **self.metrics,
            'success_rate': success_rate,
            'estimated_cost_usd': self.metrics['total_tokens_used'] * 0.00003  # Rough estimate
        }
```

---

## ðŸš€ Testing Your AI Intelligence System

Let's create realistic tests to verify the complete AI system works:

### Create AI Integration Test

Create `backend/tests/integration/test_ai_workflow.py`:

```python
"""Integration tests for complete AI workflow."""

import pytest
from unittest.mock import Mock, patch
from services.ai_intelligence import PrezIIntelligence
from models.slide import Slide
from models.ai_models import UserIntent, ActionType


@pytest.fixture
def ai_system():
    """Create complete AI system for testing."""
    return PrezIIntelligence(api_key="test-key")


@pytest.fixture
def sample_presentation_slides():
    """Create realistic presentation slides for testing."""
    return [
        Slide(
            file_id="pres1",
            slide_number=1,
            thumbnail_path="/thumbnails/title.png",
            title_text="PrezI: AI-Powered Presentation Management",
            body_text="Revolutionizing how teams create presentations",
            ai_topic="Product Introduction",
            ai_type="Title",
            ai_insight="Strong opening title introducing the product"
        ),
        Slide(
            file_id="pres1",
            slide_number=2,
            thumbnail_path="/thumbnails/problem.png",
            title_text="The Problem",
            body_text="â€¢ Manual slide management is time-consuming\nâ€¢ Finding relevant slides is difficult\nâ€¢ Presentation quality is inconsistent",
            ai_topic="Problem Statement",
            ai_type="Problem",
            ai_insight="Clear articulation of pain points that the product solves"
        ),
        Slide(
            file_id="pres1",
            slide_number=3,
            thumbnail_path="/thumbnails/solution.png",
            title_text="Our Solution",
            body_text="â€¢ AI-powered slide analysis\nâ€¢ Intelligent search and assembly\nâ€¢ Automated presentation generation",
            ai_topic="Product Solution",
            ai_type="Solution",
            ai_insight="Comprehensive solution addressing identified problems"
        ),
        Slide(
            file_id="pres1",
            slide_number=4,
            thumbnail_path="/thumbnails/market.png",
            title_text="Market Opportunity",
            body_text="â€¢ $2.5B presentation software market\nâ€¢ 20% annual growth\nâ€¢ 500M+ PowerPoint users globally",
            ai_topic="Market Analysis",
            ai_type="Data/Chart",
            ai_insight="Large addressable market with strong growth potential"
        )
    ]


class TestCompleteAIWorkflow:
    """Test the complete AI workflow from command to execution."""
    
    def test_investor_pitch_creation_workflow(self, ai_system, sample_presentation_slides):
        """Test complete workflow for creating investor pitch."""
        # Mock available slides
        ai_system.current_context = {"available_slides": sample_presentation_slides}
        
        with patch('openai.ChatCompletion.create') as mock_openai:
            # Mock intent processing response
            mock_openai.return_value = Mock()
            mock_openai.return_value.choices = [Mock()]
            mock_openai.return_value.choices[0].message.content = """{
                "primary_action": "CREATE",
                "confidence": 0.90,
                "parameters": {
                    "creation_parameters": {
                        "presentation_topic": "investor pitch",
                        "target_audience": "investors",
                        "presentation_length_minutes": 10
                    }
                }
            }"""
            
            # Process the command
            result = ai_system.process_user_command("Create an investor pitch")
            
            # Verify successful processing
            assert result.success is True
            assert result.intent.primary_action == ActionType.CREATE
            assert result.plan is not None
            assert len(result.plan.steps) > 0
    
    def test_search_command_workflow(self, ai_system, sample_presentation_slides):
        """Test search workflow for finding specific slides."""
        with patch('openai.ChatCompletion.create') as mock_openai:
            # Mock search intent response
            mock_openai.return_value = Mock()
            mock_openai.return_value.choices = [Mock()]
            mock_openai.return_value.choices[0].message.content = """{
                "primary_action": "FIND",
                "confidence": 0.85,
                "parameters": {
                    "search_parameters": {
                        "keywords": ["market", "opportunity"],
                        "slide_types": ["Data/Chart"]
                    }
                }
            }"""
            
            result = ai_system.process_user_command("Find slides about market opportunity")
            
            assert result.success is True
            assert result.intent.primary_action == ActionType.FIND
    
    def test_ambiguous_command_handling(self, ai_system):
        """Test handling of ambiguous commands requiring clarification."""
        with patch('openai.ChatCompletion.create') as mock_openai:
            # Mock low confidence response
            mock_openai.return_value = Mock()
            mock_openai.return_value.choices = [Mock()]
            mock_openai.return_value.choices[0].message.content = """{
                "primary_action": "CREATE",
                "confidence": 0.45,
                "parameters": {}
            }"""
            
            result = ai_system.process_user_command("make something")
            
            assert result.needs_clarification is True
            assert result.clarification_question is not None
    
    def test_ai_personality_consistency(self, ai_system):
        """Test that AI personality remains consistent across interactions."""
        personality = ai_system.personality
        
        # Generate multiple messages
        greetings = [personality.generate_greeting() for _ in range(3)]
        success_messages = [personality.generate_success_message("presentation") for _ in range(3)]
        
        # Verify personality traits are consistent
        for greeting in greetings:
            assert len(greeting) > 0
            assert any(word in greeting.lower() for word in ["ready", "brilliant", "create"])
        
        for success in success_messages:
            assert len(success) > 0
            assert any(word in success.lower() for word in ["done", "ready", "impress"])


class TestAIErrorHandling:
    """Test AI system error handling and recovery."""
    
    def test_openai_api_failure_recovery(self, ai_system):
        """Test recovery from OpenAI API failures."""
        with patch('openai.ChatCompletion.create') as mock_openai:
            # Simulate API failure
            mock_openai.side_effect = Exception("API rate limit exceeded")
            
            result = ai_system.process_user_command("create a presentation")
            
            # Should handle gracefully
            assert result.success is False
            assert result.error_message is not None
            assert "processing" in result.error_message.lower()
    
    def test_invalid_json_response_handling(self, ai_system):
        """Test handling of invalid JSON responses from OpenAI."""
        with patch('openai.ChatCompletion.create') as mock_openai:
            # Mock invalid JSON response
            mock_openai.return_value = Mock()
            mock_openai.return_value.choices = [Mock()]
            mock_openai.return_value.choices[0].message.content = "Invalid JSON response"
            
            result = ai_system.process_user_command("find revenue slides")
            
            # Should fall back gracefully
            assert result.intent is not None
            assert result.intent.needs_clarification is True
```

---

## ðŸŽŠ What You've Accomplished

Incredible work! You've just built PrezI's **complete AI intelligence system**:

âœ… **Natural Language Understanding** - Interprets user commands accurately  
âœ… **OODA Loop Cognitive Model** - Structured AI decision-making process  
âœ… **AI Personality System** - Professional yet engaging communication  
âœ… **Advanced Prompt Engineering** - Structured, reliable AI responses  
âœ… **Presentation Planning** - AI-generated step-by-step execution plans  
âœ… **Intent Recognition** - Distinguishes between find, create, analyze actions  
âœ… **Error Recovery** - Graceful handling of API failures and ambiguity  
âœ… **Performance Monitoring** - Tracks AI system usage and optimization  

### ðŸŒŸ The Intelligence You've Built

Your PrezI application now has:
1. **True AI Partnership** - Understands and executes complex requests
2. **Natural Communication** - Professional personality with contextual responses
3. **Strategic Planning** - Generates structured presentation strategies
4. **Adaptive Intelligence** - Learns from context and provides suggestions

**This enables:**
- Natural language presentation creation
- Intelligent slide assembly automation
- Proactive assistance and suggestions
- Professional AI communication experience

---

## ðŸŽŠ Commit Your AI Intelligence System

Let's commit this major milestone:

```bash
git add models/ services/ tests/
git commit -m "feat(ai): implement complete AI intelligence system with OODA loop

- Add natural language command processing with OpenAI API
- Implement AI personality system with contextual communication
- Create presentation planning with structured execution plans
- Add intent recognition for find, create, analyze, edit actions
- Include comprehensive error handling and recovery
- Add performance monitoring and optimization features
- Implement advanced prompt engineering with structured responses
- Create complete test coverage for AI workflows and edge cases"

git push origin main
```

---

## ðŸš€ What's Next?

In the next module, **Frontend Development with HTML/CSS/JS**, you'll:
- Build the complete user interface using HTML, CSS, and JavaScript
- Implement the design system from UXUID.md specifications  
- Create interactive slide library with drag-and-drop functionality
- Connect frontend to backend APIs with real-time communication
- Add Electron desktop application wrapper

### Preparation for Next Module
- [ ] All AI intelligence tests passing
- [ ] Understanding of AI personality and communication patterns
- [ ] Familiarity with OpenAI API integration
- [ ] AI system ready for frontend integration

---

## âœ… Module 9 Completion Checklist

Before proceeding to the next module, ensure you can:
- [ ] Process natural language commands with high accuracy
- [ ] Generate structured presentation plans using AI
- [ ] Implement personality-driven AI communication
- [ ] Handle AI errors and ambiguous commands gracefully
- [ ] Use advanced prompt engineering for reliable responses
- [ ] Monitor AI performance and optimize usage
- [ ] Integrate AI workflows with backend services

**Module Status:** â¬œ Complete | **Next Module:** [10-html-css-design-system.md](../03_frontend/10-html-css-design-system.md)

---

## ðŸ’¡ Pro Tips for AI Integration

### 1. Always Use Structured Prompts
```python
# Good - structured with schema
prompt = f"""
Analyze this command and return JSON:
Command: "{user_command}"
Schema: {{"action": "string", "confidence": "float"}}
"""

# Bad - ambiguous prompting
prompt = f"What does this mean: {user_command}"
```

### 2. Implement Confidence Thresholds
```python
if intent.confidence < 0.75:
    # Request clarification instead of guessing
    return ask_for_clarification(intent)
else:
    return execute_intent(intent)
```

### 3. Design for Error Recovery
```python
try:
    result = openai_api_call()
except RateLimitError:
    return fallback_response("API busy")
except InvalidJSONError:
    return request_clarification()
```

### 4. Monitor Performance Continuously
```python
@performance_monitor
def ai_operation():
    """Track all AI operations for optimization."""
    # Monitor tokens, response time, success rate
    pass
```